apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-collector-config-kafka
  namespace: appsentry-otel
data:
  config.yaml: |
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
      
      # Kubernetes cluster receiver
      k8s_cluster:
        collection_interval: 10s
        node_conditions_to_report: [Ready, DiskPressure, MemoryPressure, PIDPressure, NetworkUnavailable]
        distribution: kubernetes
        
      # Kubernetes objects receiver
      k8sobjects:
        objects:
          - name: pods
            mode: pull
            interval: 30s
          - name: events
            mode: watch
            
      # Host metrics receiver (for node-level metrics)
      hostmetrics:
        collection_interval: 10s
        scrapers:
          cpu:
            metrics:
              system.cpu.utilization:
                enabled: true
          memory:
            metrics:
              system.memory.utilization:
                enabled: true
          disk:
          filesystem:
          network:
          process:
            mute_process_name_error: true
            
      # Prometheus receiver for scraping metrics
      prometheus:
        config:
          scrape_configs:
            - job_name: 'appsentry-frontend'
              static_configs:
                - targets: ['appsentry-frontend:3000']
              metrics_path: /metrics
              scrape_interval: 15s
            - job_name: 'appsentry-backend'
              static_configs:
                - targets: ['appsentry-backend:3001']
              metrics_path: /metrics
              scrape_interval: 15s

    processors:
      # Batch processor for better performance
      batch:
        timeout: 1s
        send_batch_size: 5000
        send_batch_max_size: 10000
        
      # Memory limiter to prevent OOM
      memory_limiter:
        limit_mib: 512
        spike_limit_mib: 128
        check_interval: 5s
        
      # Resource processor to add/modify resource attributes
      resource:
        attributes:
          - key: deployment.environment
            value: "development"
            action: insert
          - key: service.namespace
            from_attribute: k8s.namespace.name
            action: insert
          - key: service.instance.id
            from_attribute: k8s.pod.name
            action: insert
            
      # K8s attributes processor
      k8sattributes:
        auth_type: "serviceAccount"
        passthrough: false
        filter:
          node_from_env_var: KUBE_NODE_NAME
        extract:
          metadata:
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.deployment.name
            - k8s.namespace.name
            - k8s.node.name
            - k8s.pod.start_time
        pod_association:
          - sources:
            - from: resource_attribute
              name: k8s.pod.ip
          - sources:
            - from: resource_attribute
              name: k8s.pod.uid
          - sources:
            - from: connection

    exporters:
      # Kafka exporter for traces
      kafka/traces:
        brokers:
          - kafka.appsentry-kafka.svc.cluster.local:9092
        topic: telemetry-traces
        encoding: otlp_proto
        producer:
          max_message_bytes: 1000000
          compression: snappy
      
      # Kafka exporter for metrics
      kafka/metrics:
        brokers:
          - kafka.appsentry-kafka.svc.cluster.local:9092
        topic: telemetry-metrics
        encoding: otlp_proto
        producer:
          max_message_bytes: 1000000
          compression: snappy
      
      # Kafka exporter for logs
      kafka/logs:
        brokers:
          - kafka.appsentry-kafka.svc.cluster.local:9092
        topic: telemetry-logs
        encoding: otlp_proto
        producer:
          max_message_bytes: 1000000
          compression: snappy
          
      # Keep debug exporter for development
      debug:
        verbosity: basic
        sampling_initial: 10
        sampling_thereafter: 100

    extensions:
      health_check:
        endpoint: 0.0.0.0:13133
      pprof:
        endpoint: 0.0.0.0:1777
      zpages:
        endpoint: 0.0.0.0:55679

    service:
      extensions: [health_check, pprof, zpages]
      pipelines:
        traces:
          receivers: [otlp]
          processors: [memory_limiter, k8sattributes, resource, batch]
          exporters: [kafka/traces, debug]
        metrics:
          receivers: [otlp, k8s_cluster, hostmetrics, prometheus]
          processors: [memory_limiter, k8sattributes, resource, batch]
          exporters: [kafka/metrics, debug]
        logs:
          receivers: [otlp, k8sobjects]
          processors: [memory_limiter, k8sattributes, resource, batch]
          exporters: [kafka/logs, debug]